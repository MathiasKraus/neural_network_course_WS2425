{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c01f90-ac59-44d7-90eb-13bd40b400d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krm05476/anaconda3/envs/neural-network-course/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "from model import FasterRCNN\n",
    "from data import JokesDataModule\n",
    "from helper import show_image, show_image_and_bounding_box, show_worst_image_predictions, show_confusion_matrix, get_batch, MyProgressBar\n",
    "from helper import get_sample, convert_predictions\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2574c0a-682c-466f-a965-07f3c30b29ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching articles: 100%|██████████████████████████████████████████████████| 40/40 [00:06<00:00,  6.46it/s]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "class ActorsWikipediaDataset(Dataset):\n",
    "    def __init__(self, max_articles=100):\n",
    "        self.max_articles = max_articles\n",
    "        self.articles = self._fetch_articles()\n",
    "        \n",
    "    def _fetch_articles(self):\n",
    "        url = f\"https://en.wikipedia.org/w/api.php?action=query&list=categorymembers&cmtitle=Category:Actors&cmlimit={self.max_articles}&format=json\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        article_titles = [item['title'] for item in data['query']['categorymembers']]\n",
    "        \n",
    "        articles = []\n",
    "        for title in tqdm(article_titles, desc=\"Fetching articles\"):\n",
    "            article_text = self._fetch_article_text(title)\n",
    "            if article_text:\n",
    "                articles.append(article_text)\n",
    "        \n",
    "        return articles\n",
    "    \n",
    "    def _fetch_article_text(self, title):\n",
    "        url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{title.replace(' ', '_')}\"\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get('extract', '')\n",
    "        return ''\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.articles)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.articles[idx]\n",
    "\n",
    "class TextCollate:\n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        encoding = self.tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=self.max_length)\n",
    "        input_ids = encoding['input_ids']\n",
    "        attention_mask = encoding['attention_mask']\n",
    "        return input_ids, attention_mask\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    dataset = WikipediaDataset(max_articles=100)\n",
    "    \n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    tokenizer.pad_token = tokenizer.eos_token  # Add padding token\n",
    "    \n",
    "    collate_fn = TextCollate(tokenizer)\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=8, collate_fn=collate_fn)\n",
    "    \n",
    "    for input_ids, attention_mask in dataloader:\n",
    "        print(input_ids.shape, attention_mask.shape)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "502bcd6b-de9c-422e-a25f-cf727302b976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't drink and drive, also don't call frozen yogurt \"fro yo.\"\n",
      "Who the hell decided \"have a happy period\" was an okay thing to write on maxi pads? \"NOT WORTH THE JAIL TIME\" would have been more relevant.\n",
      "Just tell me when and where and I'll be there 20 minutes late.\n",
      "I hate it when people can't make a good sausage its the wurst\n",
      "What does a dog get at the vet? [FIXED]\n",
      "Whats worse than being adopted Being adopted twice.\n",
      "David Beckham says he will retire at the end of this season, mainly because he ran out of ideas on how to do his next haircut.\n",
      "My friend asked me if I was ready to go to the nudist colony. I was born ready.\n"
     ]
    }
   ],
   "source": [
    "data_module = JokesDataModule(data_dir='data', batch_size=8, max_length=512)\n",
    "\n",
    "for input_ids, attention_mask in data_module.train_dataloader():\n",
    "    decoded_texts = [data_module.tokenizer.decode(ids, skip_special_tokens=True) for ids in input_ids]\n",
    "    for text in decoded_texts:\n",
    "        print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85110a1-508b-4eb5-94d2-d5ea39b8b275",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
