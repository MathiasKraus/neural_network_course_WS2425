{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c01f90-ac59-44d7-90eb-13bd40b400d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krm05476/anaconda3/envs/neural-network-course/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "from model import FasterRCNN\n",
    "from data import JokesDataModule\n",
    "from helper import show_image, show_image_and_bounding_box, show_worst_image_predictions, show_confusion_matrix, get_batch, MyProgressBar\n",
    "from helper import get_sample, convert_predictions\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "502bcd6b-de9c-422e-a25f-cf727302b976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kinda hard to feel sorry for myself when there's people out there who wax our private areas for a living.\n",
      "Why will there never be an Asian president? Because the American people could never make it through the erection without raughing.\n",
      "Every time you say you're humble, I want to buy you a dictionary.\n",
      "Your search - Bruno Mars not wearing a stupid hat - did not match any documents. Did you mean: Bruno Mars wearing a stupid hat.\n",
      "Why are they called Tuna Fish? Because they don't swim in pairs. Are there two of those fish? Nahhh.\n",
      "Chuck Norris crossed the road. No one has ever dared question his motives.\n",
      "Everyone is at the store buying milk and bread to prepare for the snow. I'm buying frozen pizza. Enjoy your milk sandwiches, losers!\n",
      "I would tell the one about Jonestown.. But the punch line is too long\n"
     ]
    }
   ],
   "source": [
    "data_module = JokesDataModule(data_dir='data', batch_size=8, max_length=512)\n",
    "\n",
    "for input_ids, attention_mask in data_module.train_dataloader():\n",
    "    decoded_texts = [data_module.tokenizer.decode(ids, skip_special_tokens=True) for ids in input_ids]\n",
    "    for text in decoded_texts:\n",
    "        print(text)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85110a1-508b-4eb5-94d2-d5ea39b8b275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b53c01-6ba3-4f21-8a0c-e7abc710a368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa3e6aa-4c84-4dd5-87e2-7086face30df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type            | Params | Mode\n",
      "-------------------------------------------------\n",
      "0 | model | GPT2LMHeadModel | 124 M  | eval\n",
      "-------------------------------------------------\n",
      "124 M     Trainable params\n",
      "0         Non-trainable params\n",
      "124 M     Total params\n",
      "497.759   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  15%|████▎                        | 3465/23166 [01:48<10:19, 31.79it/s, v_num=3, train_loss=2.850]"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    data_module = JokesDataModule(data_dir='data', batch_size=8, max_length=512)\n",
    "    model = GPT2FineTuner()\n",
    "    trainer = Trainer(max_epochs=3)\n",
    "    trainer.fit(model, data_module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8366b2fe-5b74-4eb0-b98d-032c52bfb4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
